{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. Data generator\n",
    "    a. Loads vocab\n",
    "    c. Loads image features\n",
    "    d. provide data for training.\n",
    "2. Build image caption model\n",
    "3. Trains the model\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import gfile\n",
    "from tensorflow import logging\n",
    "import pprint\n",
    "import _pickle as cPickle\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "input_description_file = './data/results.token'\n",
    "input_img_feature_dir = './data/download_inpcetion_v3_features/'\n",
    "input_vocab_file = './data/vocab.txt'\n",
    "output_dir = './data/local_run'\n",
    "\n",
    "if not gfile.Exists(output_dir):\n",
    "    gfile.MakeDirs(output_dir)\n",
    "    \n",
    "def get_default_params():\n",
    "    return tf.contrib.training.HParams(\n",
    "        num_vocab_word_threshold = 3,\n",
    "        num_embedding_size = 32,\n",
    "        num_timesteps = 10,\n",
    "        num_lstm_nodes = [64,64],\n",
    "        num_lstm_layers = 2,\n",
    "        num_fc_nodes = 32,\n",
    "        batch_size = 80, \n",
    "        cell_type = 'lstm',\n",
    "        clip_lstm_grads = 1, # 梯度剪切，超过的会被设置成1\n",
    "        learning_rate = 0.001,\n",
    "        keep_prob = 0.8,\n",
    "        log_frequent = 100,  # 多久打印一次log\n",
    "        save_frequent = 1000,\n",
    "    )\n",
    "hps = get_default_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3835, 389, 1, 0]\n",
      "i have a <UNK>\n"
     ]
    }
   ],
   "source": [
    "# 载入词表\n",
    "class Vocab:\n",
    "    def __init__(self, filename, word_num_threshold):\n",
    "        self._id_to_word = {}\n",
    "        self._word_to_id = {}\n",
    "        self._unk = -1\n",
    "        self._eos = -1\n",
    "        self._word_num_threshold = word_num_threshold\n",
    "        self._read_dict(filename)\n",
    "        \n",
    "    def _read_dict(self, filename):\n",
    "        with gfile.GFile(filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        for line in lines:\n",
    "            word, occurrence = line.strip('\\r\\n').split('\\t')\n",
    "            occurrence = int(occurrence)\n",
    "            if occurrence < self._word_num_threshold:\n",
    "                continue\n",
    "            idx = len(self._id_to_word)\n",
    "            if word == '<UNK>':\n",
    "                self._unk = idx\n",
    "            elif word == '.':\n",
    "                self._eos = idx\n",
    "            if word in self._word_to_id or idx in self._id_to_word:\n",
    "                raise Exception('duplicate words in vocab')\n",
    "            self._id_to_word[idx] = word\n",
    "            self._word_to_id[word] = idx\n",
    "    \n",
    "    @property\n",
    "    def unk(self):\n",
    "        return self._unk\n",
    "    \n",
    "    @property\n",
    "    def eos(self):\n",
    "        return self._eos\n",
    "    \n",
    "    def word_to_id(self, word):\n",
    "        return self._word_to_id.get(word, self._unk)\n",
    "            \n",
    "    def id_to_word(self, word_id):\n",
    "        return self._id_to_word.get(word_id, '<UNK>')\n",
    "            \n",
    "    def size(self):\n",
    "        return len(self._id_to_word)\n",
    "    \n",
    "    # 输入句子转换成词的id列表\n",
    "    def encode(self, sentence):\n",
    "        return [self.word_to_id(word) for word in sentence.split(' ')]\n",
    "             \n",
    "    # 输入id列表转换成一句话\n",
    "    def decode(self, sentence_id):\n",
    "        words = [self.id_to_word(word_id) for word_id in sentence_id]\n",
    "        return ' '.join(words)\n",
    "        \n",
    "# 测试\n",
    "vocab = Vocab(input_vocab_file, hps.num_vocab_word_threshold)\n",
    "\n",
    "encode_sentence = vocab.encode('i have a dream')\n",
    "print(encode_sentence)\n",
    "print(vocab.decode(encode_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:num of all images: 31783\n",
      "['A child in a pink dress is climbing up a set of stairs in an entry way .',\n",
      " 'A little girl in a pink dress going into a wooden cabin .',\n",
      " 'A little girl climbing the stairs to her playhouse .',\n",
      " 'A little girl climbing into a wooden playhouse .',\n",
      " 'A girl going into a wooden building .']\n",
      "INFO:tensorflow:num of all images: 31783\n",
      "[[3, 52, 4, 1, 91, 117, 8, 247, 49, 1, 366, 10, 414, 4, 27, 5350, 670, 2],\n",
      " [3, 60, 30, 4, 1, 91, 117, 356, 71, 1, 227, 3610, 2],\n",
      " [3, 60, 30, 247, 5, 414, 15, 40, 3834, 2],\n",
      " [3, 60, 30, 247, 71, 1, 227, 3834, 2],\n",
      " [3, 30, 356, 71, 1, 227, 78, 2]]\n"
     ]
    }
   ],
   "source": [
    "# 解析图片描述文件，返回(img_name, [descriptions.....])\n",
    "def parse_token_file(token_file):\n",
    "    \"\"\"parse image description file\"\"\"\n",
    "    img_name_to_tokens = {}\n",
    "    with gfile.GFile(token_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        img_id, description = line.strip('\\r\\n').split('\\t')\n",
    "        image_name, _ = img_id.split('#')\n",
    "        img_name_to_tokens.setdefault(image_name, [])\n",
    "        img_name_to_tokens[image_name].append(description)\n",
    "    return img_name_to_tokens\n",
    "\n",
    "def convert_token_to_id(img_name_to_tokens, vocab):\n",
    "    \"\"\"Converts token of each description of imgs to id\"\"\"\n",
    "    img_name_to_tokens_id = {}\n",
    "    for img_name in img_name_to_tokens:\n",
    "        img_name_to_tokens_id.setdefault(img_name, [])\n",
    "        for description in img_name_to_tokens[img_name]:\n",
    "            token_ids = vocab.encode(description)\n",
    "            img_name_to_tokens_id[img_name].append(token_ids)\n",
    "    return img_name_to_tokens_id\n",
    "\n",
    "img_name_to_tokens = parse_token_file(input_description_file)\n",
    "img_name_to_tokens_id = convert_token_to_id(img_name_to_tokens, vocab)\n",
    "\n",
    "logging.info(\"num of all images: %d\" % len(img_name_to_tokens))\n",
    "pprint.pprint(img_name_to_tokens['1000268201.jpg'])\n",
    "logging.info(\"num of all images: %d\" % len(img_name_to_tokens_id))\n",
    "pprint.pprint(img_name_to_tokens_id['1000268201.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageCaptionData:\n",
    "    \"\"\"provide data for image caption model.\"\"\"\n",
    "    def __init__(self, image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
